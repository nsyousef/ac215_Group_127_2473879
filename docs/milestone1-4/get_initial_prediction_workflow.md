# get_initial_prediction Workflow

This document traces the complete workflow of `get_initial_prediction` from the frontend UI through to the Python backend and back.

## Frontend Flow

### 1. User Interaction (`AddDiseaseFlow.jsx`)

**Entry Point:** User clicks "Analyze" button
- **Function:** `handleStartAnalysis()` (line 245)
- **Action:** Calls `analyzeImage()` (line 264)

### 2. Analysis Process (`AddDiseaseFlow.jsx` - `analyzeImage()`)

**Line 121:** `setAnalyzing(true)` - Sets analyzing state flag

**Line 170:** `setStep(5)` - **Shows "Analyzing..." UI**
- Step 5 renders (lines 420-429):
  - CircularProgress spinner
  - "Analyzing..." text
  - "Please wait while we analyze your image" message

**Line 173:** `await mlClient.getInitialPrediction(...)` - **BLOCKING CALL**
- This is a Promise that waits for the entire prediction to complete
- During this wait, the UI is stuck on step 5 (analyzing screen)
- No streaming chunks are displayed here

**After completion:**
- **Line 223:** `setAnalyzing(false)` - Clears analyzing flag
- **Line 226:** `close()` - Closes the AddDiseaseFlow dialog
- **Line 232-234:** `onStartAnalysis(newDisease)` - Navigates to results/chat view

### 3. ML Client (`mlClient.js`)

**Line 63-78:** `getInitialPrediction()` method
- **Line 68:** Calls `window.electronAPI.mlGetInitialPrediction()`
- This is the **non-streaming** version
- Returns a Promise that resolves with the complete result object

**Note:** There's also `getInitialPredictionStream()` (line 93) but it's **not used** by AddDiseaseFlow

### 4. Electron Preload (`preload.js`)

**Line 11-17:** `mlGetInitialPrediction` function
- Calls `ipcRenderer.invoke('ml:getInitialPrediction', ...)`
- Returns a Promise that resolves when Python sends the final result

### 5. Electron Main Process (`main.js`)

**Line 243-254:** `ipcMain.handle('ml:getInitialPrediction', ...)`
- **Line 246:** Calls `pyRequest(caseId, 'predict', ...)`
- **Line 250:** Provides `onChunk` callback that sends chunks via:
  ```javascript
  event.sender.send('ml:streamChunk', { chunk })
  ```
- **Important:** These chunks are sent, but AddDiseaseFlow is **NOT listening** to them
- The chunks are only consumed by `ChatPanel.jsx` (see below)

### 6. Python Backend (`ml_server.py`)

**Line 98-117:** `handle_message()` for `cmd == "predict"`
- **Line 107-109:** Creates `on_stream_chunk` callback that sends chunks via `send({"id": req_id, "chunk": text})`
- **Line 112-116:** Calls `manager.get_initial_prediction(...)` **WITH** `on_chunk=on_stream_chunk`
- **✅ Streaming IS enabled** at the Python level
- Chunks are sent to Node.js via stdout JSON protocol

### 7. Python API Manager (`api_manager.py`)

**Line 545-656:** `get_initial_prediction()` method
- **Line 622:** Calls `_call_llm_explain()` with optional `on_chunk` parameter
- **Line 967-1008:** `_call_llm_explain()` makes streaming request to Modal endpoint
- **Line 1000:** Calls `on_chunk(chunk)` for each streaming chunk
- But since `ml_server.py` doesn't pass a callback, chunks are not forwarded

## Current Behavior

1. ✅ User sees "Analyzing..." screen (step 5) immediately
2. ❌ Streaming chunks are **NOT displayed** during analysis
3. ✅ UI waits for complete result (blocking)
4. ✅ After completion, dialog closes and navigates to results

## Where Streaming Chunks ARE Used

**ChatPanel.jsx (lines 117-160):**
- Subscribes to `ml:streamChunk` events via `mlOnStreamChunk`
- Displays streaming chunks in the chat interface
- **But:** This only works AFTER the initial prediction completes and the chat view is shown

## Summary

**Current Flow:**
```
User clicks "Analyze"
  → setStep(5) [Shows "Analyzing..."]
  → await getInitialPrediction() [BLOCKS - waits for everything]
  → close() [Closes dialog]
  → onStartAnalysis() [Navigates to results]
```

**Streaming chunks are:**
- ✅ Generated by Python backend
- ✅ Sent via IPC (`ml:streamChunk` events)
- ❌ **NOT displayed** during AddDiseaseFlow
- ✅ Only displayed in ChatPanel after navigation

**To enable streaming during analysis:**
1. ✅ Python already passes `on_chunk` callback (done in `ml_server.py` line 116)
2. ❌ Update `AddDiseaseFlow.jsx` to subscribe to `ml:streamChunk` events
3. ❌ Display streaming chunks in the analyzing step (step 5)

**Current Status:**
- ✅ Streaming works at Python level
- ✅ Chunks are sent via IPC (`ml:streamChunk` events)
- ❌ AddDiseaseFlow doesn't listen to chunks (only ChatPanel does)
- ✅ After navigation, ChatPanel can display the streamed content
