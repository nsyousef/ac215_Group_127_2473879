# Simple Modal Training Configuration - Quick Test Run

# Data source configuration  
data:
  use_local: False  # Use GCS paths directly (gs://)
  metadata_path: "gs://derma-datasets-2/final/metadata_all_harmonized.csv"
  img_prefix: "gs://derma-datasets-2/final/imgs"
  min_samples_per_label: 50  # Lower threshold for faster loading
  datasets: null  # null = use all datasets (not just fitzpatrick17k)
  data_fraction: 0.01  # Use 10% of data (stratified by label) for quick testing
  has_text: null
  
  # Data splits
  test_size: 0.2
  val_size: 0.1
  
  # Image configuration
  img_size: [224, 224]
  seed: 42

# Training parameters - MINIMAL for quick test
training:
  batch_size: 8  # Smaller batch for quick test
  num_workers: 0
  prefetch_factor: 1
  num_epochs: 3  # Just 3 epochs for testing
  patience: 10
  validation_interval: 1
  n_warmup_epochs: 1  # Quick warmup
  
  compute_stats: False
  weighted_sampling: False
  
  scheduler:
    use_cosine_annealing: false  # Disable for simplicity
    # eta_min values only used if use_cosine_annealing is true

# Minimal augmentation
augmentation:
  brightness_jitter: 0.1
  contrast_jitter: 0.1
  saturation_jitter: 0.1
  hue_jitter: 0.02
  rotation_degrees: 10
  translate: null
  scale: null
  grayscale_prob: null
  horizontal_flip_prob: 0.5
  vertical_flip_prob: null

# Simple vision model
vision_model:
  name: "resnet50"
  pretrained: true
  pooling_type: "max"
  unfreeze_layers: 10  # Fewer layers for faster training

# Simple multimodal classifier
multimodal_classifier:
  
  # Simple projection
  projection_dim: 128  # Smaller dimension
  image_projection_hidden: [256]  # Single hidden layer
  projection_activation: "relu"
  projection_dropout: 0.2
  
  text_projection_hidden: [256]  # Single hidden layer
  
  # Simple final classifier
  final_hidden_sizes: [64]  # Single hidden layer
  final_activation: "relu"
  final_dropout: 0.3
  
  fusion_strategy: "weighted_sum"
  
  # Disable auxiliary losses for simplicity
  use_auxiliary_loss: false
  auxiliary_loss_weight: 0.0
  
  loss_fn: "cross_entropy"
  label_smoothing: 0.0  # No smoothing for simplicity

# Encoder configuration
encoder:
  pre_existing_path: null
  model_name: "pubmedbert"
  max_length: 512
  pooling_type: "cls"
  batch_size: 32
  qwen_instr: "Represent the patient's description and characteristics (including clinical details, age, sex, and symptoms) as a semantic embedding suitable for clinical classification. Return an embedding."

# Optimizer configuration
optimizer:
  vision_model:
    name: "adamw"
    learning_rate: 0.0001
    weight_decay: 0.0001
    momentum: 0.9
    betas: [0.9, 0.999]
    eps: 0.00000001
  
  multimodal_classifier:
    name: "adamw"
    learning_rate: 0.001
    weight_decay: 0.0001
    momentum: 0.9
    betas: [0.9, 0.999]
    eps: 0.00000001

# Output configuration
output:
  save_dir: "/checkpoints"
  log_dir: "./logs"
  experiment_name: "test_run"
  wandb_project: "APCOMP215"

# Checkpoint configuration
checkpoint:
  save_frequency: 10
  keep_last: 1
  load_from: null